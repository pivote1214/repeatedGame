\documentclass[submit]{ipsj}


\usepackage[dvipdfmx]{graphicx} 
\usepackage{amsmath,amssymb}
\usepackage{enumerate}
\usepackage{amsthm}
\usepackage{cite}
\usepackage{bm}
\usepackage{array}
\usepackage{booktabs}
\usepackage{subcaption}
\theoremstyle{definition}
\newtheorem{definition}{定義}
\newtheorem*{definition*}{定義}
\graphicspath{{figure}}


\begin{document}

\title{3状態以下有限オートマトンを用いた私的観測\\
繰り返しゲームにおける進化的安定戦略}

\etitle{An Analysis on Evolutionary Stability of Strategies\\
Using 3-State or Less Finite Automata\\
in Repeated Games with Private Monitoring}

\affiliate{Shako}{筑波大学理工学群社会工学類\\
College of Policy and Planning Sciences, University of Tsukuba}

\affiliate{MShako}{筑波大学システム情報系社会工学域\\
Graduate School of Systems and Information Engineering, University of Tsukuba}

\author{森 勇太}{Mori Yuta}{Shako}
\author{澤 亮治}{Sawa Ryoji}{MShako}

\begin{abstract}
私的観測繰り返し囚人のジレンマゲームにおける
進化的安定戦略の分析を行った．
私的観測とは，
相手の行動を見ることができない代わりに
相手の行動に依存する不確実なシグナルを受け取り，
それを他人は見ることができない状況を指す．
Cooper(1996, Journal of Economic Theory)の定義を私的観測に拡張し，
3状態以下の有限オートマトンで表される戦略について，
数値解析により
進化的安定な有限オートマトン戦略を判定した．
その結果，
2-MP（2期相互処罰）戦略が高い利得を達成しながら進化的安定になることが判明した．
さらに，$k \le 5$の$k$-MP戦略について，
進化的安定の追加検証を行い，
3-MPが最も広いエラー率の範囲で進化的安定になり，
複雑さのコストに関する頑健性は2-MPが最も高いことが判明した．
\end{abstract}

\begin{jkeyword}
  私的観測，繰り返しゲーム，有限オートマトン，進化的安定戦略，$k$-MP，変更
\end{jkeyword}

\begin{eabstract}
We analyze evolutionary stability of strategies
in repeated prisoner's dilemma games with private monitoring.
Private monitoring refers to settings 
where players cannot observe other players' actions perfectly,
but instead receive noisy signals about their actions.
We extend the definition of evolutionary stability
in Cooper (1996, Journal of Economic Theory)
to repeated games with private monitoring, 
and examine evolutionary stability of (up to three-state) finite automata
via a numerical analysis.
We find that seven types of automata are evolutionarily stable,
and the 2-MP (Two-period Mutual Punishment) is evolutionarily stable while achieving high payoffs.
Furthermore,
we examine evolutionary stability of $k$-MP with $k \le 5$.
The result shows that
3-MP is evolutionarily stable over the widest range of error rates,
and 2-MP is the most robust to the cost of the number of states.
\end{eabstract}

\begin{ekeyword}
  private monitoring, repeated game, finite automata, evolutionarily stable strategies, $k$-MP
\end{ekeyword}

\maketitle

\section{序論} \label{sec:introduction}

囚人のジレンマに代表される集団に対して非協力的な行動が個人的に最適となる状況で，
人が協力する仕組みの解明は経済学，生物学など他分野にまたがった
学際的な研究課題である．
繰り返しゲームは，
短期的な関係では実現することが難しい
囚人のジレンマなどにおける相互の協力が，
長期的な関係になると達成できることを
説明する有力なモデルである．
協力を達成するためには，
プレイヤが相手の行動を
ある程度観測できることが必要である．
繰り返しゲームの研究は，
相手の行動が完全に観測できる完全観測，
相手の行動の代わりに全員が同じ公的シグナルを観測する公的不完全観測，
相手の行動が完全には観測できず
各人が相手の行動に関して個別にシグナルを観測する私的不完全観測の3つに分類される．
この中で，
私的不完全観測の状況が最も分析が困難とされている\cite{Kandori-2015,Sugaya-2022}．
私的不完全観測の状況で，
均衡の実現しやすさや攪乱に対する安定性など均衡の頑健性については，
十分にわかっていない．

繰り返しゲームにおける戦略は，
前期までに観察された情報に今期の行動を対応させる写像として一般に定義される．
しかし，無限繰り返しゲームにおいては
戦略の記述が無限長になりえるため，
有限オートマトンによる簡略表現がよく用いられる\cite{muto-2013}．
また，
有限オートマトン表現により，
戦略の記述に必要な状態数を
その戦略の複雑さと捉えることができ，
人間の限定合理性をモデルに組み込むことが可能となる\cite{Rubinstein-1986}．
本研究では，
繰り返しゲームにおける戦略集合を
3状態以下の有限オートマトンで表される戦略に限定し，
分析を行う．
繰り返しゲームの経済実験では
2状態の有限オートマトンで表現できる戦略がよく観察されており，
状態数の制限はあるが
一定の現実性を持つ戦略集合である\cite{DalBo-2011}．

本研究では，
私的観測繰り返し囚人のジレンマゲームにおける，
3状態以下有限オートマトンで表される戦略の
安定性を検証する．
具体的には，
進化的安定戦略（Evolutionarily Stable Strategy，以下 ESS）の概念を用いて
局所的に安定な戦略を同定する．
ESSは，
ESSの戦略を全プレイヤが採用している状態では
他の戦略が侵入することができないという種類の
局所的な安定性を持つ\cite{Smith-1973}．
本研究の貢献は，
私的観測繰り返し囚人のジレンマゲームにおいて，
3状態以下のマシンの
ESS戦略を数値解析によって同定した点である．
この数値解析によって，
低〜中程度のエラー率で$k$期相互処罰（$k$-MP）戦略の特殊ケースである2-MP戦略が，
広いエラー率でマシン492，892が，
高いエラー率でマシン35が，
中〜高程度のエラー率かつ低い割引因子でマシン896が，
広いパラメータ設定でAll-Dが
ESSになることがわかった．
上記のマシン492,892は
一定の条件を満たすと常に非協力行動をとり続ける
トリガー戦略の一種である．
また，
2-MPは高い利得を達成しながら進化的安定となり，
複雑さのコストに対しても頑健であることがわかった．
そこで，
4状態以上の有限オートマトンで表される，
$k$-MP戦略の相互罰の期間$k = 3, 4, 5$の戦略について，
ESS判定の追加検証を行った．
その結果，
3-MPが最も広いエラー率でESSとなり，
2-MPが最も複雑さのコストに対して頑健であることがわかった．

有限オートマトンを用いた
囚人のジレンマの繰り返しゲーム（以降，マシンゲーム）について
ESSなど局所的安定性の観点から行われた関連研究を述べる．
文献\cite{Rubinstein-1986}，\cite{Abreu-1988}は，マシンゲームのナッシュ均衡の理論分析を行っている．
文献\cite{Binmore-1992}，\cite{Cooper-1996}は
有限オートマトンの状態数を複雑さとみなし，複雑さを考慮したESSによる
ナッシュ均衡の頑健性判定を行った．
文献\cite{Binmore-1992}は，
第1に利得，第2に複雑さの少なさを優先する
辞書式選好を導入したESSを提案している．
文献\cite{Cooper-1996}は，
複雑さに対する明示的なコストを仮定し，
状態数に比例したコストを差し引いた利得を用いる
ESSを提案している．
上記研究は完全観測の状況を対象としているが，
文献\cite{koike-2022}が
文献\cite{Binmore-1992}のESS定義を援用し，
私的観測の状況における
進化的安定戦略の分析を行っている．
文献\cite{koike-2022}では
戦略を2状態以下有限オートマトンに限定しているが，
本研究は戦略を3状態以下まで拡張している．
この拡張により，
表現可能な戦略が
26種類から1054種類まで大幅に増加している．
また，
本研究では
進化的安定戦略として，
文献\cite{Cooper-1996}のESS定義を援用する．

不完全観測の状況については，
文献\cite{Nowak-1995}が
エラーを含む有限オートマトン戦略の安定性を分析している．
エラー率を0に近づけた極限の利得では，
All-D，Grim Trigger（以下，GT），Pavlov戦略が
広い利得の範囲で駆逐されない戦略となる
\footnote{厳密な定義ではないが，駆逐されない戦略は，
すべての他の戦略$s$に対して，
(i) $s$に侵入されないか，(ii) $s$に侵入できるかのいずれかの性質を持つ．}．
文献\cite{Nowak-1995}では
有限オートマトンの状態を直接遷移させるエラーが起こると仮定している．
本研究では，エラーによる状態遷移は
相手の行動を見誤る観測エラーを介した遷移のみを仮定している点が異なる．
文献\cite{Posch-1999}は，
2状態以下の有限オートマトンを対象に，
本研究と同様に相手の行動を見誤るタイプのエラーを仮定している．
エラー確率を0に近づけた極限の利得を用い，
一定の利得条件の下でPavlov戦略のみが
進化的に安定となることを示した．
本研究では，
利得設定は限定し，
エラー率の変動による進化的安定性への影響を検証している．

不完全観測のマシンゲームの進化動学の分析は，
他に文献\cite{nishino-2020}, \cite{yotsuji-2021}, \cite{igarashi-2021}などがある．
文献\cite{nishino-2020}は
2状態以下の有限オートマトンを戦略とした
レプリケータダイナミクスの帰結から，
出現しやすい戦略を分析した．
文献\cite{yotsuji-2021}は，
エラー率の変動および損失回避性の有無による
進化的安定性への影響を分析している．
文献\cite{igarashi-2021}は
2人のプレイヤがお互いの見間違えをほぼ共有するという公的観測に近い状況を仮定している．
そのような状況ではPavlov戦略が生き残り戦略とならないことを示した．
上記研究は2状態以下のオートマトンを分析対象としているが，
本研究は3状態オートマトンまで対象を拡張している点が主な違いとなる．

進化的安定性は他の戦略が侵入できない性質の安定性であるが，
この性質に近い均衡の同定手法に私的観測繰り返しゲームの
信念ベースアプローチと呼ばれる手法がある．
これは，均衡どおりの行動をとるインセンティブがある均衡を同定する手法である．
% この手法については，文献\cite{Kandori-2010}が，
部分観測マルコフ決定過程を利用して，
有限オートマトンが私的観測繰り返しゲームの
逐次均衡となる判定法を示した．
文献\cite{joyonjun-2012}は
% 文献\cite{Kandori-2010}の考えを用いて
3状態以下の有限オートマトンで構成される均衡を数値分析した．
文献\cite{joyonjun-2012}では，
マシンの状態数にかかるコストは考慮されておらず，
本研究ではESSマシンについて複雑さのコストを導入した．


\section{モデル} \label{sec:model}

\subsection{私的観測繰り返し囚人のジレンマゲーム} \label{sec:model-game}

文献\cite{koike-2022}を参考に，
ゲームの定式化を行う．
プレイヤ集合を$N = \{1, 2\}$，
プレイヤ$i \in N$の行動集合を$A_i = \{C, D\}$，
プレイヤ$i \in N$が受け取るシグナルの集合を$\Omega_i = \{g, b\}$とする．
$\Omega_i$は，プレイヤ$i$が相手の行動を観測する代わりに受け取るシグナル$\omega_i$の集合である．
2人のプレイヤの行動のペア$\bm{a} = (a_1, a_2)$を行動プロファイルと呼び，
2人が受け取るシグナルのペア$\bm{\omega} = (\omega_1, \omega_2)$をシグナルプロファイルと呼ぶ．
シグナルプロファイルは行動プロファイルに依存して確率的に決定され，
$o(\bm{\omega}|\bm{a})$をその（同時）確率分布とする．
観測にエラーがない場合には，プレイヤ$i \neq j \in N$について，
$a_j = C$の場合には$\omega_i = g$，$a_j = D$の場合には$\omega_i = b$となるとする．
また，プレイヤ$i$の利得は自身の行動$a_i$と観測したシグナル$\omega_i$にのみ依存する．
関数$\pi_i : A_i \times \Omega_i \rightarrow \mathbb{R}$を利得関数とし，
各$i \in N$について以下の利得を仮定する．
\begin{eqnarray}
  \pi_i(C, g) = 3, & \quad & \pi_i(C, b) = 0,\notag \\
  \pi_i(D, g) = 4, & \quad & \pi_i(D, b) = 1 \notag
\end{eqnarray}
文献\cite{koike-2022,Binmore-1992}との比較を容易にするため，
同様の利得設定とした．
ゲームは囚人のジレンマの構造を持つ．
どのシグナルに対しても行動$D$が常に最適な行動となるが，
お互いが行動$D$を選んだ際の利得は，お互いが行動$C$を選んだ際の利得よりも小さい．
また，
$2 \pi_i(C, g) > \pi_i(D, g) + \pi_i(C, b)$であり，
$(C, C)$を続ける方が$(D, C)$, $(C, D)$を繰り返すよりも双方にとって良い．

行動プロファイル$\bm{a}$のときのプレイヤ$i$の期待利得は，
\[ g_i(\bm{a}) = \sum_{\omega \in \Omega_1 \times \Omega_2} \pi_i(a_i, \omega_i) o(\bm{\omega}, \bm{a}) \]
と表せる．

シグナル$\omega$については，
誤ったシグナルが発生するエラー率を$p$とした
互いに独立したシグナルを各プレイヤが受け取ると仮定する．
つまり，
$a_j = C$の場合には$\omega_i = b$，
$a_j = D$の場合には$\omega_i = g$となる事象が
確率$p$で発生する．
例として，
行動プロファイル$\bm{a} = (C,C)$のシグナル確率を以下に示す．
\begin{eqnarray}
  o((g, g)|(C, C)) &=& (1 - p)^2, \nonumber \\
  o((b, g)|(C, C)) &=& p (1 - p), \nonumber \\
  o((g, b)|(C, C)) &=& (1 - p) p, \nonumber \\
  o((b, b)|(C, C)) &=& p^2 \nonumber
\end{eqnarray}
本研究では，
仮定する相関のない独立したシグナルを受け取ると仮定する．
同様の仮定は，文献\cite{koike-2022}でも用いられている．
%自分が受け取ったシグナルから相手のシグナルの推測も可能となるが，このような推測に関する戦略性を分析に含めず，誤りを含むシグナルに対する反応とその帰結を分析のメイン対象とする．また2人の受け取るシグナルの精度$1 - p$には差がないとした．

プレイヤは上記のゲームを無限回繰り返す．
プレイヤ$i$の$t \in \{1, 2, \ldots\}$期までの過去の行動と
受けとったシグナルの記録を$i$の私的履歴と呼び，
$\bm{h}_{i}^{t} = (a_{i}^{1}, \omega_{i}^{1}, \ldots, a_{i}^{t}, \omega_{i}^{t}) $で表す．
ここで，
$a_{i}^{s}$はプレイヤ$i$の $s$期の行動を，
$\omega_{i}^{s}$は$i$が$s$期に受け取ったシグナルを示す．
無限回繰り返しゲームにおけるプレイヤの純粋戦略$s_i$は，
$H_{i}^t := (A_i \times \Omega_i)^t$とおくと，
$s_i := H_i \rightarrow A_i$と表せる．
ここで，
$t + 1$期の行動は$s_i(\bm{h}_{t}^{i})$で与えられる．
割引因子$\delta \in (0, 1)$とし，
無限繰り返しゲームの期待利得を以下のように表す（$\bm{h}_{i}^{0}$は空集合とする）．
\begin{equation}
  f_i(s_1, s_2) = (1 - \delta) E \left[ \sum_{t=0}^{\infty} \delta^{t} g_i(s_1(\bm{h}_{1}^{t}), s_2(\bm{h}_{2}^{t})) \right] \nonumber
\end{equation}

\subsection{純粋戦略の有限オートマトン表現} \label{sec:model-automata}

本研究では，
\ref{sec:model-game}節の
私的観測繰り返しゲームの戦略を
3状態以下有限オートマトンの戦略に限定し，分析を行う．
以下では，
有限オートマトンで表現される戦略をマシンと呼び，
戦略を有限オートマトンに限定したゲームをマシンゲームと呼ぶ．
オートマトンは各状態でとる行動，
および相手から受け取るシグナルに対する状態遷移の規則を定め，
毎期にとる行動を決める．
プレイヤ$i$の用いるマシンを$m_i$とし，
$m_i = \langle Q_i, q_{i}^{0}, \lambda_i, \mu_i \rangle$の4つの要素で表す．
$Q_i$はマシン$m_i$における有限の状態集合，
$q_{i}^{0}$はマシン$m_i$の初期状態($q_{i}^{0} \in Q_i$)である．
$\lambda_i \colon Q_i \rightarrow A_i$は行動決定関数であり，
状態$q_i \in Q_i$から行動$a_i \in A_i$を返す．
$\mu_i \colon Q_i \times \Omega_i \rightarrow Q_i$は状態遷移関数であり，
自分の状態$q_i \in Q_i$と受け取ったシグナル$\omega_i \in \Omega_i$から
次の期の自身の状態$q_i \in Q_i$を返す．
マシンゲームにおける利得は以下のように表せる．
\begin{equation} \label{eq:machine-game-payoff}
  P_i(m_1, m_2) = (1 - \delta) E \left[ \sum_{t=0}^{\infty} \delta^{t} g_i(\lambda_1(q_{1}^{t}), \lambda_2(q_{2}^{t})) \right]
\end{equation}
ここで，
$q_{i}^{t}$は$t$期でのプレイヤ$i$のマシンの状態を示す．
マシン$m_i$の複雑さを状態数の大きさ$|Q_i|$と定義する．
また，
$M$を状態数が3以下の1,054個のマシンの集合とする
\footnote{初期状態のみが異なるマシンは区別し，実質的に同じ振る舞いをするオートマトンを除く}．
つまり，
\begin{equation}
  M = \{m = \langle Q_i, q_{i}^{0}, \lambda_i, \mu_i \rangle \colon |Q_i| \le 3\} \nonumber
\end{equation}
である．
以下の分析では，
$M$が各プレイヤの戦略集合となる．
また，
以降では便宜的にマシン$m \in M$の複雑さを$|m|$と表す．


\section{進化的安定性の数値解析判定} \label{sec:ess}

\subsection{進化的安定戦略} \label{sec:def-ess}

進化的安定戦略の定義を不完全観測のマシンゲームに拡張する．
Cooper(1996)は，複雑さに明示的なコストがかかるとし，
進化的安定戦略を定義した．
1状態あたりにかかるコストを$\alpha$とし，
利得を
\begin{align}
  U_i(m_1, m_2) = P_i(m_1, m_2) - \alpha |m_i| \nonumber
\end{align}
とする．
この利得$U_i$を用いて，
進化的安定戦略（以下，ESS-CC）を定義する．
\begin{definition} \label{def:ESS-CC}
  $m^{\ast} \in M$がESS-CCであるとは，
  $\forall m \neq m^{\ast} \in M$に対して
  以下の(\ref{item:ESS-CC-1})，(\ref{item:ESS-CC-2})の条件の
  いずれかが成り立つことをいう．
  \begin{enumerate}[(I)]
    \item $U_1(m^{\ast}, m^{\ast}) > U_1(m, m^{\ast})$ \label{item:ESS-CC-1}
    \item $U_1(m^{\ast}, m^{\ast}) = U_1(m, m^{\ast})$ and $U_1(m^{\ast}, m) > U_1(m, m)$ \label{item:ESS-CC-2}
  \end{enumerate}
\end{definition}

利得$U_1$が完全観測のマシンゲームの利得であれば，
この定義はCooper(1996)のESSと一致する．
条件(\ref{item:ESS-CC-1})は
マシン$m^{\ast}$同士の状態から別のマシン$m$へ逸脱すると利得が減少することを意味する．
条件(\ref{item:ESS-CC-2})はマシン$m$は$m^{\ast}$との対戦から得る利得が
マシン$m^{\ast}$同士が対戦した利得と等しいが，
マシン$m$どうしの対戦から得る利得は
$m^{\ast}$が$m$の対戦から得る利得よりも低いことを意味する．
つまり，
条件(\ref{item:ESS-CC-1})または(\ref{item:ESS-CC-2})が成り立つ場合には，
すべてのプレイヤが$m^{\ast}$を採用している状況で
$m$へ逸脱した（複数かつ少数の）プレイヤの利得は
必ず他のプレイヤより低くなる．

文献\cite{koike-2022}は，
Binmore and Samuelson(1992)のESS定義を援用し，
以下のように
利得を第1，複雑さを第2の優先順位として
進化的安定戦略（ESS）を定義した．
\begin{definition} \label{def:ESS}
  $m^{\ast} \in M$がESSであるとは，
  $\forall m \neq m^{\ast} \in M$ に対して
  以下の(\ref{item:ESS-1})，(\ref{item:ESS-2})，(\ref{item:ESS-3})の条件の
  いずれかが成り立つことをいう．
  \begin{enumerate}[(I)]
    \item $P_1(m^{\ast}, m^{\ast}) > P_1(m, m^{\ast})$ \label{item:ESS-1}
    \item $P_1(m^{\ast}, m^{\ast}) = P_1(m, m^{\ast})$ and $P_1(m^{\ast}, m) > P_1(m, m)$ \label{item:ESS-2}
    \item $P_1(m^{\ast}, m^{\ast}) = P_1(m, m^{\ast})$, $P_1(m^{\ast}, m) = P_1(m, m)$ and $|m^{\ast}| < |m|$ \label{item:ESS-3}
  \end{enumerate}
\end{definition}

$\alpha = 0$であれば，
ESS-CCの(\ref{item:ESS-CC-1})，(\ref{item:ESS-CC-2})と
ESSの(\ref{item:ESS-1})，(\ref{item:ESS-2})は一致する．
条件(\ref{item:ESS-3})は，
条件(\ref{item:ESS-2})までの利得がそれぞれ同じとき，
$m^{\ast}$の状態数は$m$の状態数より小さくなければならないことを意味する．
複雑さにかかるコストを非常に微小であると仮定し，
利得が同じであれば複雑さの少ない側が有利との想定をした条件となる．

本研究では，
進化的安定なマシンの中でも
複雑さのコストに対して頑健であるマシンを同定するため，
進化的安定戦略の判定に
定義\ref{def:ESS-CC}のESS-CCを用いる．

\subsection{ESS-CC判定手法} \label{sec:judge-method-ESS-CC}

数値解析によるESS-CC判定手法を述べる．
繰り返しゲームの最終期は$T = 1,000$とした．
つまり，
式(\ref{eq:machine-game-payoff})の無限回$\infty$を
1,000に置き換えた利得を判定に使用する．
また，
観測ノイズにより利得が確率的となるため，
$T = 1,000$のマシンゲームを5,000回行い，
5,000回の利得の平均値を期待利得$P_i$として用いた．
割引因子$\delta = 0.99, \ 0.95$，
エラー率$1 \sim 20 \%$（1\%ごと）の
各パラメータ設定で判定を行う．
はじめに，
複雑さに対してコストがかからない，
つまり，
$\alpha = 0$の場合について判定を行う．
この判定によって
広いパラメータでESS-CCと判定されたマシンについて
ESS-CCとなる$\alpha$の範囲を同定する．

\subsection{数値解析結果} \label{sec:result}

\begin{table}[tb]
  \centering
  \caption{$\alpha = 0$におけるESS-CC判定結果（\%はエラー率）}
  \ecaption{ESS-CC identification result for $\alpha = 0$ \\
  (The numbers with  denote the error rates).}
  \label{tab:ESS-CC-alpha-0}
  \begin{tabular}{l|rr} \hline\hline
    マシン番号 & $\delta = 0.99$ & $\delta = 0.95$ \\ \hline
    26(All-D) & $4, 7, 11, 14, 16, 20 \%$ & $3, 5, 7 \sim 17, 19, 20\%$ \\
    35 & $14 \sim 20\%$ & $17 \sim 20\%$ \\
    408(2-MP) & $2 \sim 11\%$ & $1 \sim 10\%$ \\
    492 & $1 \sim 18\%$ & $4 \sim 17\%$ \\
    896 & $13 \sim 19\%$ & $10 \sim 19\%$ \\ \hline
  \end{tabular}
\end{table}

\begin{figure}
  \centering
  \begin{minipage}{0.225\textwidth}
    \centering
    \includegraphics[scale=0.150]{machine-26.png}
    \caption{All-D}
    \ecaption{All-D}
    \label{fig:All-D}
  \end{minipage}
  \hfill
  \begin{minipage}{0.225\textwidth}
    \centering
    \includegraphics[scale=0.150]{machine-35.png}
    \caption{マシン35}
    \ecaption{machine 35}
    \label{fig:machine-35}
  \end{minipage}
\end{figure}

\begin{figure}
  \centering
  \begin{minipage}{0.225\textwidth}
    \centering
    \includegraphics[scale=0.150]{machine-408.png}
    \caption{マシン408（2-MP）}
    \ecaption{machine 408(2-MP)}
    \label{fig:2-MP}
  \end{minipage}
  \hfill
  \begin{minipage}{0.225\textwidth}
    \centering
    \includegraphics[scale=0.150]{machine-492.png}
    \caption{マシン492}
    \ecaption{machine 492}
    \label{fig:machine-492}
  \end{minipage}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[scale=0.150]{machine-896}
  \caption{マシン896}
  \ecaption{machine 896}
  \label{fig:machine-896}
\end{figure}

本論文では，
特に広いパラメータ設定においてESS-CCと判定された
8種類のマシンのみを取り扱う．
ESS-CCとなるオートマトンは
割引因子$\delta$およびエラー率$p$に依存し，
\tabref{tab:ESS-CC-alpha-0}に
$\alpha = 0$における
各パラメータ設定での
8種類のマシンのESS-CC判定結果を示す．
また，
ESS-CCと判定されたオートマトンの一部を
\figref{fig:All-D}〜\figref{fig:machine-896}に示す．
表内のマシン番号は
図に示した各オートマトンと対応している．
図の各オートマトンの円は状態を示し，
円の状態にあるときは円内に示された行動を選ぶ．
また，
3状態のマシンについては，
グレーで塗りつぶされた状態は初期状態を，
矢印は各シグナル$g, b$を受け取った際の状態遷移を表す．
以後，
初期状態を状態1，
真ん中（マシン492は右上）の状態を状態2，
右（マシン492は右下）の状態を状態3と呼ぶことにする．

以下で各オートマトンについて説明する．
マシン26（\figref{fig:All-D}）は
永久に行動$D$を取り続けるAll-D戦略と呼ばれる戦略である．
マシン35（\figref{fig:machine-35}）は，
はじめは行動$C$を取り続けるが，
2期続けてシグナル$b$を観測することがトリガーとなり，
その後は永久に行動$D$を取り続けるマシンである．
マシン492（\figref{fig:machine-492}）は，
状態1で行動$C$をとり，
シグナル$g$を観測すると状態2に遷移する．
状態2では
行動$D$を取り，
どちらのシグナルを観測しても状態1に戻る．
状態1でシグナル$b$を観測するとその後，
永久に行動$D$を取りづづける状態3に遷移する．
マシン892は，
マシン492と初期状態のみが異なり，
状態2が初期状態となったものである．
マシン896（\figref{fig:machine-896}）は，
初期状態で行動$D$を取り，
どちらのシグナルを観測しても状態3に遷移する．
状態3では
行動$C$を取り続けるが，
一度でもシグナル$b$を観測すると
その後は永久に行動$D$を取り続ける状態2に遷移する．
以上の4つのマシン35，492，892，896を，
特定の条件がトリガーとなり，
その後永久に裏切り続けるという点から，
以後まとめてトリガー戦略と呼ぶ．

マシン408（\figref{fig:2-MP}）は，
自分が協力状態のときにシグナル$g$を受け取ると，
その状態にとどまり，
シグナル$b$を受け取ると離反の状態に遷移する．
その後，
シグナル$b$を2回続けて観測したときのみ
協力状態にもどる．
マシン547とマシン736は
マシン408と初期状態のみが異なり，
マシン547はマシン408の状態2が，
マシン736はマシン408の状態3が
初期状態となったマシンである．
一般に，
協力状態では相手の協力が続く限り協力を続け，
相手の裏切りを観測すると裏切る．
その後，
$k$期連続お互いに裏切りが続くと協力に戻る戦略を
$k$期相互罰戦略（$k$-MP）といい\cite{joyonjun-2012}，
マシン408，547，736は，
その$k = 2$の特殊ケースである．
以後，
これら3マシンを2-MPと呼ぶ．

\begin{figure*}[tb]
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\columnwidth]{ESSCC-099.png}
    \caption{割引因子$\delta = 0.99$におけるESS-CC判定結果}
    \ecaption{ESS-CC identification result\\
    for the discount factor $\delta = 0.99$}
    \label{fig:ESS-CC-099}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\columnwidth]{ESSCC-095.png}
    \caption{割引因子$\delta = 0.95$におけるESS-CC判定結果}
    \ecaption{ESS-CC identification result\\
    for the discount factor $\delta = 0.95$}
    \label{fig:ESS-CC-095}
  \end{minipage}
\end{figure*}

$\alpha = 0$のパラメータ設定でESS-CCと判定されたマシンについて，
各パラメータ設定で
ESS-CCの境界となる$\alpha$の同定を行った．
マシン892はマシン492と，
マシン547とマシン736はマシン408との
違いが初期状態のみであるため，
マシン26（All-D），35，408（2-MP），492，896の4つのマシンのみを分析対象とする．
All-D以外の4つのマシンについて，
各割引因子におけるESS-CCとなるエラー率（横軸）と
1状態にかかるコスト（縦軸）の範囲を
\figref{fig:ESS-CC-099}，\figref{fig:ESS-CC-095}に示す．

\subsection{考察} \label{sec:consideration}

\begin{figure*}[tb]
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\columnwidth]{payoff-same-099}
    \caption{割引因子$\delta = 0.99$の利得変化}
    \ecaption{Relationship between payoffs and error rates\\
    for discount factor $\delta = 0.99$}
    \label{fig:payoff-same-099}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\columnwidth]{payoff-same-095}
    \caption{割引因子$\delta = 0.95$の利得変化}
    \ecaption{Relationship between payoffs and error rates\\
    for discount factor $\delta = 0.95$}
    \label{fig:payoff-same-095}
  \end{minipage}
\end{figure*}


各割引因子において，
ESS-CCと判定されたマシンが
同じマシン同士で対戦したときの
エラー率（横軸）と利得（縦軸）の関係を
\figref{fig:payoff-same-099}，\figref{fig:payoff-same-095}に示す．
これらの図より，
2-MPは低〜中程度のエラー率において，
高い利得とESS達成を両立していることがわかる．
2-MP同士の対戦を考えると，
エラーがない限りは相互協力を続けることができる．
また，
エラーによってシグナル$b$を観測したとしても
協力行動に復帰することができる．
例えば，
マシン408同士の対戦で，
お互いに協力している状態からエラーによって
プレイヤ1がシグナル$b$を観測し，
状態2に遷移したとする．
その後エラーが起こらないと仮定すると，
シグナル$b$を観測したプレイヤ1は，
次の期に行動$D$を取り，
プレイヤ2は行動$C$を取る．
プレイヤ2はシグナル$b$を観測し，
状態2に遷移する．
プレイヤ1は状態2にとどまる．
その次の期にお互いに行動$D$を取り，
双方が状態3に遷移する．
次の期もお互いに行動$D$を取ることで，
双方が行動$C$をとる状態1に同時に遷移する．
つまり，
エラー後の行動プロファイルは$(D, C), (D, D), (D, D), (C, C)$となり，
相互協力に復帰することができる．
この相互協力的で，
かつ同じマシンに対してエラーが起きても相互協力に復帰することができる性質が
2-MPが高利得を達成する要因になっている．
エラー率が高くなるほど，
相互に行動$D$を取り合う回数が多くなり，
2-MP同士の対戦による利得は減少する．

2-MPは
All-Dなどの基本的に行動$D$を取り続けるマシンに対しても
中程度のエラー率までは侵入を受けない．
2-MPとAll-Dの対戦では，
エラーがない限り$(C, D), (D, D), (D, D)$と，
2-MPが3回に1回行動$C$を，
3回に2回行動$D$を取るサイクルが続く．
これによって，
All-D側の利得はおおよそ2となる．
この利得は，
エラー率によって大きく変わることはない．
一方，
2-MP同士が対戦したときの利得は
エラー率が大きくなるにつれ小さくなる．
そのため，
自身との対戦で得られる利得がおおよそ2を下回るエラー率までは，
2-MPはAll-Dの侵入を受けない．

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.45\textwidth]{GTvs35-099.png}
  \caption{GTとマシン35}
  \ecaption{GT and machine 35}
  \label{fig:GTvs35-099}
\end{figure}
\begin{figure}
  \centering
  \includegraphics[scale=0.20]{machine-4.png}
  \caption{Grim Trigger}
  \ecaption{Grim Trigger}
  \label{fig:Grim-Trigger}
\end{figure}

次に，
トリガー戦略について考える．
これらのマシンは，
All-Dなどの行動$D$を取り続ける相手に対しては，
すぐに永久離反の状態に遷移するため，
侵入を受けにくい．
そこで，
ESSとならないGT（\figref{fig:Grim-Trigger}）について考察する．
割引因子$\delta = 0.99$における，
GT同士の対戦と，
マシン35がGTと対戦したときの
エラー率（横軸）と利得（縦軸）の関係を図\figref{fig:GTvs35-099}に示す．
GTは
1度のシグナル$b$がトリガーとなる一方，
マシン35は2連続のシグナル$b$がトリガーとなる．
GT同士の対戦の場合，
どちらかのプレイヤが間違ったシグナルを観測すると，
それ以降は永久に行動$D$を取り合うことになる．
一方，
マシン35とGTの対戦においては，
GT側が間違ったシグナルを観測した場合，
それ以降は永久に行動$D$を取り合うことになるが，
マシン35の側が間違ったシグナルを観測しても，
もう一度行動$C$を続けるため
相互協力の状態を長く保つことができる．
エラー率が高くなると
相互協力を保てる期間が短くなるため，
GT同士の対戦利得と
マシン35がGTと対戦したときの利得は同程度になる．
つまり，
GTは低〜中程度のエラー率で
トリガーがより寛容なマシンの侵入を受ける．
同様の議論は，
全てのトリガー戦略についても当てはまる．
そのため，
3状態以下のマシンのもとで進化的安定とされたマシンも
戦略空間を広げることで
振る舞いが自分と似た，
トリガーがより寛容な戦略の侵入を受けることが予想される．

3状態のマシンは，
1状態にかかるコスト$\alpha$が大きくなると，
2状態以下のマシンに対する相対的な利得は減少する．
そのため，
3状態のマシンについては，
$\alpha = 0$でESS-CCとなるエラー率において，
ESS-CCとなる$\alpha$の上界が得られる．
$\alpha$の上界が高いほど，
マシンは状態数のコストに関して頑健である．
\figref{fig:ESS-CC-099}，\figref{fig:ESS-CC-095}から，
2-MPは低〜中程度のエラー率において最も状態数のコストに関して頑健であり，
エラー率が高くなるにつれて頑健性は弱まることがわかる．
2-MP同士の対戦では
特に低いエラー率において
高い利得を達成し，
また，
All-Dなどの行動$D$を取り続けるマシンに対しては十分に報復できる性質から
2-MP同士の対戦による利得と
2状態以下のマシンが2-MPと対戦したときの利得の差が大きいことが要因である．
また，
マシン35は高程度のエラー率で最も状態数のコストに関して頑健であり，
同様にエラー率が高くなるにつれて頑健性は弱まる．
マシン35同士の対戦では，
2回続けてエラーが起きるまで協力を続けることで
高い利得を達成する一方，
All-Dなどの行動$D$を取り続ける戦略に対しては
基本的に3期目以降は行動$D$を続けることができるため，
2-MPの場合と同様に
マシン35同士の対戦による利得と
2状態以下のマシンがマシン35と対戦したときの利得の差が大きいことが要因である．
マシン492は広いエラー率でESS-CCとなるが，
頑健性は他のマシンに比べて弱い．
また，
割引因子$\delta = 0.95$では，
割引因子$\delta = 0.99$に比べて，
低いエラー率ではESS-CCと判定されない一方，
中〜高程度のエラー率ではESS-CCとなる$\alpha$の範囲が広くなる．
最後に，
マシン896は
割引因子$\delta = 0.99$のときはESS-CCとなる範囲が狭いが，
割引因子$\delta = 0.95$では，
中程度のエラー率でESS-CCとなる範囲が最も広い．
\ref{sec:result}節の分析により
$\alpha = 0$において
各マシンが進化的に安定となるエラーの範囲を特定したが，
進化的に安定となるエラー範囲であっても
境界部分に近づくほど頑健性が弱まるという点が
本分析により確認された．

最後に，
All-Dについて述べる．
All-Dは
$\alpha=0$ではエラー率によらず
広いパラメータ設定で，
特に割引因子$\delta=0.95$においてESS-CCと判定された．
また，
All-Dは1状態のマシンであるため，
1状態のかかるコスト$\alpha$が大きくなると，
その他のマシンに対する相対的な利得は増加する．
そのため，
ESS-CCとなる$\alpha$の下界が得られ，
分析の結果，
すべてのパラメータ設定において
$\alpha=0.002$でESS-CCと判定されることがわかった．
これは非常に小さな$\alpha$であり，
All-Dが$\alpha=0$において
ESS-CCと判定されなかったパラメータ設定においては
All-Dと非常によく似た振る舞いをするマシンに対して
僅かな利得の差で侵入を受けると判定されたことが
原因であると考えられる．
つまり，
All-Dはすべてのパラメータ設定において，
進化的安定または
進化的安定に非常に近いということが示唆される．

\section{$k$期相互罰戦略の相互罰の期間$k$} \label{sec:k-MP}

\subsection{相互罰の期間$k$} \label{sec:punishment-k}

$k$-MPの特殊ケースである2-MPは，
同じマシン同士の対戦において高い利得を達成しながら，
ESSとも判定された．
また，
ESSと判定された他のマシンに比べて
低〜中程度のエラー率では
複雑さのコストに関しても頑健であることがわかった．
この理由は，
\ref{sec:consideration}節でも述べたとおり，
2-MP同士の対戦ではエラーが起きても協力に復帰でき，
All-Dなどの行動$D$を取り続けるマシンに対しては
十分に報復することができる性質にあった．
相互罰の期間が長くなると
相互協力的な性質は弱まり，
All-Dなどのマシンに対する頑健性の性質は強くなる．
そのため，
相互罰の期間$k$の長さがESSの判定にどのような影響を与えるかは自明でない．
そこで，
3状態以下のマシンに対する，
3-MP，4-MP，5-MPのESS-CC判定の追加検証を行う．

\subsection{$k$-MPのESS，ESS-CC判定手法} \label{sec:judge-method-ESS-CC-kMP}

数値解析による
$k$-MPのESS判定手法を述べる．
$k$-MPのマシンとして，
簡単のため，
初期状態で行動$C$を取るマシンを採用した．
例えば，
1-MPとしてマシン3を，
2-MPとしてマシン408を用いた．
\ref{sec:judge-method-ESS-CC}節と同様，
$T = 1,000$のマシンゲーム5,000回分の平均値を
期待利得$P_i$として用いる．
割引因子$\delta = 0.99,\ 0.95$
およびエラー率$1 \sim 20\%$（1\%ごと）の各パラメータ設定で，
各マシンがESS-CCとなる，
1状態にかかるコスト$\alpha$の範囲を同定する．

\subsection{結果・考察}

\begin{table}[tb]
  \centering
  \caption{$\alpha = 0$における$k$-MPのESS-CC判定結果（\%はエラー率）}
  \ecaption{ESS-CC identification result of $k$-MP for $\alpha = 0$ \\
  (The numbers with  denote the error rates).}
  \label{tab:ESS-CC-kMP-alpha-0}
  \begin{tabular}{l|rr} \hline\hline
    マシン & $\delta = 0.99$ & $\delta = 0.95$ \\ \hline
    1-MP & $4 \sim 5\%$ & -- \\
    2-MP(2-MP) & $2 \sim 11\%$ & $1 \sim 10\%$ \\
    3-MP & $1 \sim 11\%$ & $1 \sim 11\%$ \\
    4-MP(2-MP) & $1 \sim 11\%$ & $1 \sim 10\%$ \\
    5-MP & $1 \sim 11\%$ & $1 \sim 9\%$ \\ \hline
  \end{tabular}
\end{table}

\begin{figure*}[t]
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\columnwidth]{ESSCC-kMP-099.png}
    \caption{割引因子$\delta = 0.99$における$k$-MPのESS-CC判定結果}
    \ecaption{ESS-CC identification result of $k$-MP\\
    for the discount factor $\delta = 0.99$}
    \label{fig:ESS-CC-kMP-099}
  \end{minipage}
  \hfill
  \begin{minipage}{0.45\textwidth}
    \centering
    \includegraphics[width=\columnwidth]{ESSCC-kMP-095.png}
    \caption{割引因子$\delta = 0.95$における$k$-MPのESS-CC判定結果}
    \ecaption{ESS-CC identification result of $k$-MP\\
    for the discount factor $\delta = 0.95$}
    \label{fig:ESS-CC-kMP-095}
  \end{minipage}
\end{figure*}

$\alpha = 0$における
各$k$-MPマシンのESS-CC判定結果を\tabref{tab:ESS-CC-kMP-alpha-0}に示す．
また，各割引因子における
ESS-CCとなるエラー率（横軸）と1状態にかかるコスト（縦軸）の範囲を
\figref{fig:ESS-CC-kMP-099}，\figref{fig:ESS-CC-kMP-095}に示す．

\begin{figure}[t]
  \centering
  \includegraphics[width=0.45\textwidth]{kMPvs35.png}
  \caption{3,5-MPとマシン35}
  \ecaption{3,5-MP and machine 35}
  \label{fig:kMP-vs-35}
\end{figure}

判定の結果を考察する．
\tabref{tab:ESS-CC-kMP-alpha-0}から，
3-MPから相互罰の期間を長くすると，
特に割引因子$\delta = 0.95$において，
ESSと判定されるエラー率の範囲が狭くなっていることがわかる．
これについては，
マシン35との対戦が鍵になる．
割引因子$\delta = 0.95$における，
3-MP同士，5-MP同士，
また，
マシン35が3-MP，5-MPと対戦したときの
エラー率と利得の関係を\figref{fig:kMP-vs-35}に示す．
この図から，
5-MPがマシン35に侵入されるエラー率の範囲は，
3-MPがマシン35に侵入されるエラー率の範囲よりも広いことがわかる．
相互罰の期間が長くなると，
行動$D$を取る回数が多くなるため，
マシン35が5-MPと対戦したときの利得は，
3-MPと対戦したときの利得よりも低くなる．
また，
前述の通り，
5-MP同士の対戦による利得は，
3-MP同士の対戦の利得よりも低くなる．
この利得が低下する度合いが，
マシン35が5-MPと対戦したときよりも
5-MP同士の対戦のほうが大きいことから，
5-MPがESSとなるエラー率の範囲は，
3-MPがESSとなるエラー率の範囲よりも小さくなる．

さらに，
\figref{fig:ESS-CC-kMP-099}，\figref{fig:ESS-CC-kMP-095}から，
かなり低いエラー率では1-MPが，
低〜中程度のエラー率では2-MPが
最も複雑さのコストに関する頑健性が高いことがわかる．
つまり，
2-MPからさらに相互罰の期間を伸ばすことによるメリットは，
状態数にかかるコストに比べてそれほど大きくない．
この傾向は特に，
割引因子$\delta = 0.95$において顕著である．

\section{結論}

本研究では，
私的観測繰り返しゲームにおける，
3状態以下の有限オートマトンで表される戦略の
局所的な安定性を検証した．
さまざまなエラー率における，
数値解析によるESS戦略の同定を行い，
特に広いエラー率でESSと判定された8つの戦略を取り上げた．
本論文のエラーの設定のもとでは，
3状態以下の環境で進化的安定と判定されたトリガー戦略は
戦略空間を広げることで
より寛容な戦略に侵入を受けることが示唆された．
また，
All-Dは
すべてのパラメータ設定において
進化的安定に非常に近くいことがわかった．
さらに，
低〜中程度のエラー率で2-MP戦略が
高い利得を達成しながら進化的安定にもなることがわかった．
そこで，
2-MP戦略が特殊ケースとして含まれる$k$-MP戦略の
相互罰の期間$k$に関する\ref{sec:k-MP}章の分析を行い，
$k$-MPの中でも2-MP，3-MPが最もパフォーマンスが良く，
相互罰の期間が長いほど進化的安定となりやすいわけではないことがわかった．

本研究の課題は，
観測エラーを乱数発生させるシミュレーションのため，
確定的な判定とはならず，
誤差が生じた点である．
シミュレーション回数の増加や，
他の手法を用いた利得計算の検討の必要がある．
また，
進化動学のシミュレーションを用いて，
均衡からの乖離が大きい状態から
進化的に安定な戦略を用いる均衡への収束を検証する，
大域的安定性の検証も課題である．
実際，
進化的安定性という局所的な安定性を持つ戦略が，
実は大域的な安定性を持たず
進化シミュレーションなどで出現しにくいことがある\cite{koike-2022}．

% 参考文献
\bibliographystyle{ipsjunsrt}
\bibliography{main}

\end{document}
†
